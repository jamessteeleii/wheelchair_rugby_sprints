
@article{amrhein_scientists_2019,
	title = {Scientists rise up against statistical significance},
	volume = {567},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-019-00857-9},
	doi = {10.1038/d41586-019-00857-9},
	abstract = {Valentin Amrhein, Sander Greenland, Blake McShane and more than 800 signatories call for an end to hyped claims and the dismissal of possibly crucial effects.},
	language = {en},
	number = {7748},
	urldate = {2022-10-05},
	journal = {Nature},
	author = {Amrhein, Valentin and Greenland, Sander and McShane, Blake},
	month = mar,
	year = {2019},
	note = {Bandiera\_abtest: a
Cg\_type: Comment
Number: 7748
Publisher: Nature Publishing Group
Subject\_term: Research data, Research management},
	keywords = {Research data, Research management},
	pages = {305--307},
	file = {Full Text PDF:C\:\\Users\\james\\Zotero\\storage\\6H2GHXJ9\\Amrhein et al. - 2019 - Scientists rise up against statistical significanc.pdf:application/pdf;Snapshot:C\:\\Users\\james\\Zotero\\storage\\GPSJZBM6\\d41586-019-00857-9.html:text/html},
}

@article{amrhein_inferential_2019,
	title = {Inferential {Statistics} as {Descriptive} {Statistics}: {There} {Is} {No} {Replication} {Crisis} if {We} {Don}’t {Expect} {Replication}},
	volume = {73},
	issn = {0003-1305},
	shorttitle = {Inferential {Statistics} as {Descriptive} {Statistics}},
	url = {https://doi.org/10.1080/00031305.2018.1543137},
	doi = {10.1080/00031305.2018.1543137},
	abstract = {Statistical inference often fails to replicate. One reason is that many results may be selected for drawing inference because some threshold of a statistic like the P-value was crossed, leading to biased reported effect sizes. Nonetheless, considerable non-replication is to be expected even without selective reporting, and generalizations from single studies are rarely if ever warranted. Honestly reported results must vary from replication to replication because of varying assumption violations and random variation; excessive agreement itself would suggest deeper problems, such as failure to publish results in conflict with group expectations or desires. A general perception of a “replication crisis” may thus reflect failure to recognize that statistical tests not only test hypotheses, but countless assumptions and the entire environment in which research takes place. Because of all the uncertain and unknown assumptions that underpin statistical inferences, we should treat inferential statistics as highly unstable local descriptions of relations between assumptions and data, rather than as providing generalizable inferences about hypotheses or models. And that means we should treat statistical results as being much more incomplete and uncertain than is currently the norm. Acknowledging this uncertainty could help reduce the allure of selective reporting: Since a small P-value could be large in a replication study, and a large P-value could be small, there is simply no need to selectively report studies based on statistical results. Rather than focusing our study reports on uncertain conclusions, we should thus focus on describing accurately how the study was conducted, what problems occurred, what data were obtained, what analysis methods were used and why, and what output those methods produced.},
	number = {sup1},
	urldate = {2022-10-05},
	journal = {The American Statistician},
	author = {Amrhein, Valentin and Trafimow, David and Greenland, Sander},
	month = mar,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2018.1543137},
	keywords = {Auxiliary hypotheses, Confidence interval, Hypothesis test, P-value, Posterior probability, Replication, Selective reporting, Significance test, Statistical model, Unreplicable research},
	pages = {262--270},
	file = {Full Text PDF:C\:\\Users\\james\\Zotero\\storage\\GPJHZUMZ\\Amrhein et al. - 2019 - Inferential Statistics as Descriptive Statistics .pdf:application/pdf},
}

@article{mcshane_abandon_2019,
	title = {Abandon {Statistical} {Significance}},
	volume = {73},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2018.1527253},
	doi = {10.1080/00031305.2018.1527253},
	abstract = {We discuss problems the null hypothesis significance testing (NHST) paradigm poses for replication and more broadly in the biomedical and social sciences as well as how these problems remain unresolved by proposals involving modified p-value thresholds, confidence intervals, and Bayes factors. We then discuss our own proposal, which is to abandon statistical significance. We recommend dropping the NHST paradigm—and the p-value thresholds intrinsic to it—as the default statistical paradigm for research, publication, and discovery in the biomedical and social sciences. Specifically, we propose that the p-value be demoted from its threshold screening role and instead, treated continuously, be considered along with currently subordinate factors (e.g., related prior evidence, plausibility of mechanism, study design and data quality, real world costs and benefits, novelty of finding, and other factors that vary by research domain) as just one among many pieces of evidence. We have no desire to “ban” p-values or other purely statistical measures. Rather, we believe that such measures should not be thresholded and that, thresholded or not, they should not take priority over the currently subordinate factors. We also argue that it seldom makes sense to calibrate evidence as a function of p-values or other purely statistical measures. We offer recommendations for how our proposal can be implemented in the scientific publication process as well as in statistical decision making more broadly.},
	number = {sup1},
	urldate = {2022-10-05},
	journal = {The American Statistician},
	author = {McShane, Blakeley B. and Gal, David and Gelman, Andrew and Robert, Christian and Tackett, Jennifer L.},
	month = mar,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2018.1527253},
	keywords = {Null hypothesis significance testing, p-Value, Replication, Sociology of science, Statistical significance},
	pages = {235--245},
	file = {Full Text PDF:C\:\\Users\\james\\Zotero\\storage\\MFCQLH52\\McShane et al. - 2019 - Abandon Statistical Significance.pdf:application/pdf},
}

@article{cumming_new_2014,
	title = {The {New} {Statistics}: {Why} and {How}},
	volume = {25},
	issn = {0956-7976},
	shorttitle = {The {New} {Statistics}},
	url = {https://doi.org/10.1177/0956797613504966},
	doi = {10.1177/0956797613504966},
	abstract = {We need to make substantial changes to how we conduct research. First, in response to heightened concern that our published research literature is incomplete and untrustworthy, we need new requirements to ensure research integrity. These include prespecification of studies whenever possible, avoidance of selection and other inappropriate data-analytic practices, complete reporting, and encouragement of replication. Second, in response to renewed recognition of the severe flaws of null-hypothesis significance testing (NHST), we need to shift from reliance on NHST to estimation and other preferred techniques. The new statistics refers to recommended practices, including estimation based on effect sizes, confidence intervals, and meta-analysis. The techniques are not new, but adopting them widely would be new for many researchers, as well as highly beneficial. This article explains why the new statistics are important and offers guidance for their use. It describes an eight-step new-statistics strategy for research with integrity, which starts with formulation of research questions in estimation terms, has no place for NHST, and is aimed at building a cumulative quantitative discipline.},
	language = {en},
	number = {1},
	urldate = {2022-10-05},
	journal = {Psychological Science},
	author = {Cumming, Geoff},
	month = jan,
	year = {2014},
	note = {Publisher: SAGE Publications Inc},
	pages = {7--29},
	file = {SAGE PDF Full Text:C\:\\Users\\james\\Zotero\\storage\\V346TNH8\\Cumming - 2014 - The New Statistics Why and How.pdf:application/pdf},
}

@article{kruschke_bayesian_2018,
	title = {The {Bayesian} {New} {Statistics}: {Hypothesis} testing, estimation, meta-analysis, and power analysis from a {Bayesian} perspective},
	volume = {25},
	issn = {1531-5320},
	shorttitle = {The {Bayesian} {New} {Statistics}},
	url = {https://doi.org/10.3758/s13423-016-1221-4},
	doi = {10.3758/s13423-016-1221-4},
	abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed “the New Statistics” (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
	language = {en},
	number = {1},
	urldate = {2022-10-05},
	journal = {Psychonomic Bulletin \& Review},
	author = {Kruschke, John K. and Liddell, Torrin M.},
	month = feb,
	year = {2018},
	keywords = {Bayes factor, Bayesian inference, Confidence interval, Credible interval, Effect size, Equivalence testing, Highest density interval, Meta-analysis, Null hypothesis significance testing, Power analysis, Randomized controlled trial, Region of practical equivalence},
	pages = {178--206},
	file = {Full Text PDF:C\:\\Users\\james\\Zotero\\storage\\ZC6EX7YU\\Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf:application/pdf},
}

@misc{wickham_ggplot2_2022,
	title = {ggplot2: {Create} {Elegant} {Data} {Visualisations} {Using} the {Grammar} of {Graphics}},
	copyright = {MIT + file LICENSE},
	shorttitle = {ggplot2},
	url = {https://CRAN.R-project.org/package=ggplot2},
	abstract = {A system for 'declaratively' creating graphics, based on "The Grammar of Graphics". You provide the data, tell 'ggplot2' how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.},
	urldate = {2022-10-05},
	author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey and RStudio},
	month = may,
	year = {2022},
	keywords = {Spatial, TeachingStatistics},
}

@misc{pedersen_patchwork_2022,
	title = {patchwork: {The} {Composer} of {Plots}},
	copyright = {MIT + file LICENSE},
	shorttitle = {patchwork},
	url = {https://CRAN.R-project.org/package=patchwork},
	abstract = {The 'ggplot2' package provides a strong API for sequentially building up a plot, but does not concern itself with composition of multiple plots. 'patchwork' is a package that expands the API to allow for arbitrarily complex composition of plots by, among others, providing mathematical operators for combining multiple plots. Other packages that try to address this need (but with a different approach) are 'gridExtra' and 'cowplot'.},
	urldate = {2022-10-05},
	author = {Pedersen, Thomas Lin},
	month = aug,
	year = {2022},
}

@misc{kay_tidybayes_2022,
	title = {tidybayes: {Tidy} {Data} and '{Geoms}' for {Bayesian} {Models}},
	copyright = {GPL (≥ 3)},
	shorttitle = {tidybayes},
	url = {https://CRAN.R-project.org/package=tidybayes},
	abstract = {Compose data for and extract, manipulate, and visualize posterior draws from Bayesian models ('JAGS', 'Stan', 'rstanarm', 'brms', 'MCMCglmm', 'coda', ...) in a tidy data format. Functions are provided to help extract tidy data frames of draws from Bayesian models and that generate point summaries and intervals in a tidy format. In addition, 'ggplot2' 'geoms' and 'stats' are provided for common visualization primitives like points with multiple uncertainty intervals, eye plots (intervals plus densities), and fit curves with multiple, arbitrary uncertainty bands.},
	urldate = {2022-10-05},
	author = {Kay, Matthew and Mastny, Timothy},
	month = jan,
	year = {2022},
}

@article{burkner_brms_2017,
	title = {brms: {An} {R} {Package} for {Bayesian} {Multilevel} {Models} {Using} {Stan}},
	volume = {80},
	copyright = {Copyright (c) 2017 Paul-Christian Bürkner},
	issn = {1548-7660},
	shorttitle = {brms},
	url = {https://doi.org/10.18637/jss.v080.i01},
	doi = {10.18637/jss.v080.i01},
	abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit  -  among others  -  linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
	language = {en},
	urldate = {2023-07-27},
	journal = {Journal of Statistical Software},
	author = {Bürkner, Paul-Christian},
	month = aug,
	year = {2017},
	keywords = {Bayesian inference, MCMC, multilevel model, ordinal data, R, Stan},
	pages = {1--28},
	file = {Full Text:C\:\\Users\\james\\Zotero\\storage\\JLWNDQQH\\Bürkner - 2017 - brms An R Package for Bayesian Multilevel Models .pdf:application/pdf},
}
